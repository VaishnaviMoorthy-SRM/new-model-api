{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1250/1250 [==============================] - 10s 6ms/step - loss: 128.7676 - mae: 8.9021 - val_loss: 67.9095 - val_mae: 6.7458 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 70.3511 - mae: 6.8797 - val_loss: 65.8371 - val_mae: 6.6655 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 69.2366 - mae: 6.8376 - val_loss: 65.5209 - val_mae: 6.7093 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 68.4903 - mae: 6.8015 - val_loss: 65.5899 - val_mae: 6.6794 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 68.4053 - mae: 6.8032 - val_loss: 65.5615 - val_mae: 6.7235 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 68.0957 - mae: 6.7799 - val_loss: 65.3450 - val_mae: 6.6591 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "1250/1250 [==============================] - 14s 12ms/step - loss: 67.9334 - mae: 6.7847 - val_loss: 65.0598 - val_mae: 6.6500 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 67.6864 - mae: 6.7757 - val_loss: 65.0691 - val_mae: 6.6511 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 67.5863 - mae: 6.7642 - val_loss: 65.0979 - val_mae: 6.6675 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 67.3613 - mae: 6.7568 - val_loss: 65.3204 - val_mae: 6.6896 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 67.3980 - mae: 6.7561 - val_loss: 65.1168 - val_mae: 6.6535 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "1250/1250 [==============================] - 13s 11ms/step - loss: 67.2045 - mae: 6.7538 - val_loss: 65.3667 - val_mae: 6.6744 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 67.1460 - mae: 6.7448 - val_loss: 65.0591 - val_mae: 6.6721 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 67.0519 - mae: 6.7418 - val_loss: 65.2413 - val_mae: 6.6353 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 67.0353 - mae: 6.7446 - val_loss: 65.0781 - val_mae: 6.6626 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 67.0234 - mae: 6.7358 - val_loss: 65.0749 - val_mae: 6.6616 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 66.9899 - mae: 6.7414 - val_loss: 65.2129 - val_mae: 6.6422 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 67.0454 - mae: 6.7413 - val_loss: 65.0093 - val_mae: 6.6493 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "1250/1250 [==============================] - 12s 9ms/step - loss: 66.9841 - mae: 6.7313 - val_loss: 64.9892 - val_mae: 6.6183 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "1250/1250 [==============================] - 12s 10ms/step - loss: 66.9368 - mae: 6.7364 - val_loss: 65.2037 - val_mae: 6.6323 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 66.8839 - mae: 6.7393 - val_loss: 64.9991 - val_mae: 6.6621 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 67.0117 - mae: 6.7395 - val_loss: 65.3397 - val_mae: 6.6482 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 66.8933 - mae: 6.7305 - val_loss: 65.1271 - val_mae: 6.6401 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 66.8222 - mae: 6.7377 - val_loss: 65.0942 - val_mae: 6.6395 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 66.8921 - mae: 6.7352 - val_loss: 65.0481 - val_mae: 6.6566 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 66.9082 - mae: 6.7334 - val_loss: 65.1591 - val_mae: 6.6689 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 66.7172 - mae: 6.7250 - val_loss: 65.0414 - val_mae: 6.6362 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 66.7232 - mae: 6.7246 - val_loss: 65.1776 - val_mae: 6.6537 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 66.7714 - mae: 6.7271 - val_loss: 65.3497 - val_mae: 6.6101 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "1250/1250 [==============================] - 14s 11ms/step - loss: 66.5772 - mae: 6.7143 - val_loss: 64.9700 - val_mae: 6.6529 - lr: 2.0000e-04\n",
      "Epoch 31/200\n",
      "1250/1250 [==============================] - 13s 10ms/step - loss: 66.6200 - mae: 6.7187 - val_loss: 64.9712 - val_mae: 6.6536 - lr: 2.0000e-04\n",
      "Epoch 32/200\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 66.6341 - mae: 6.7204 - val_loss: 64.9469 - val_mae: 6.6499 - lr: 2.0000e-04\n",
      "Epoch 33/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 66.5244 - mae: 6.7174 - val_loss: 64.9957 - val_mae: 6.6333 - lr: 2.0000e-04\n",
      "Epoch 34/200\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 66.6610 - mae: 6.7200 - val_loss: 64.9424 - val_mae: 6.6458 - lr: 2.0000e-04\n",
      "Epoch 35/200\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 66.4991 - mae: 6.7201 - val_loss: 64.9400 - val_mae: 6.6400 - lr: 2.0000e-04\n",
      "Epoch 36/200\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 66.5205 - mae: 6.7206 - val_loss: 64.9518 - val_mae: 6.6397 - lr: 2.0000e-04\n",
      "Epoch 37/200\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 66.4917 - mae: 6.7101 - val_loss: 64.9973 - val_mae: 6.6703 - lr: 2.0000e-04\n",
      "Epoch 38/200\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 66.5110 - mae: 6.7153 - val_loss: 64.9360 - val_mae: 6.6457 - lr: 2.0000e-04\n",
      "Epoch 39/200\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 66.6107 - mae: 6.7224 - val_loss: 64.9327 - val_mae: 6.6397 - lr: 2.0000e-04\n",
      "Epoch 40/200\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 66.5199 - mae: 6.7118 - val_loss: 64.9245 - val_mae: 6.6387 - lr: 2.0000e-04\n",
      "Epoch 41/200\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 66.5350 - mae: 6.7164 - val_loss: 64.9327 - val_mae: 6.6525 - lr: 2.0000e-04\n",
      "Epoch 42/200\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 66.4286 - mae: 6.7062 - val_loss: 64.9279 - val_mae: 6.6319 - lr: 2.0000e-04\n",
      "Epoch 43/200\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 66.4784 - mae: 6.7107 - val_loss: 64.9274 - val_mae: 6.6448 - lr: 2.0000e-04\n",
      "Epoch 44/200\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 66.4936 - mae: 6.7147 - val_loss: 64.9324 - val_mae: 6.6544 - lr: 2.0000e-04\n",
      "Epoch 45/200\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 66.4523 - mae: 6.7127 - val_loss: 64.9312 - val_mae: 6.6516 - lr: 2.0000e-04\n",
      "Epoch 46/200\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 66.5524 - mae: 6.7207 - val_loss: 64.9294 - val_mae: 6.6491 - lr: 2.0000e-04\n",
      "Epoch 47/200\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 66.7074 - mae: 6.7262 - val_loss: 64.9429 - val_mae: 6.6543 - lr: 2.0000e-04\n",
      "Epoch 48/200\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 66.5379 - mae: 6.7141 - val_loss: 64.9478 - val_mae: 6.6596 - lr: 2.0000e-04\n",
      "Epoch 49/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 66.5882 - mae: 6.7254 - val_loss: 64.9251 - val_mae: 6.6543 - lr: 2.0000e-04\n",
      "Epoch 50/200\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 66.5199 - mae: 6.7127 - val_loss: 64.9365 - val_mae: 6.6576 - lr: 2.0000e-04\n",
      "Epoch 51/200\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 66.6077 - mae: 6.7263 - val_loss: 64.9154 - val_mae: 6.6479 - lr: 4.0000e-05\n",
      "Epoch 52/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 66.3794 - mae: 6.7080 - val_loss: 64.9236 - val_mae: 6.6416 - lr: 4.0000e-05\n",
      "Epoch 53/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 66.3684 - mae: 6.7115 - val_loss: 64.9228 - val_mae: 6.6516 - lr: 4.0000e-05\n",
      "Epoch 54/200\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 66.3960 - mae: 6.7067 - val_loss: 64.9197 - val_mae: 6.6507 - lr: 4.0000e-05\n",
      "Epoch 55/200\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 66.4639 - mae: 6.7123 - val_loss: 64.9144 - val_mae: 6.6432 - lr: 4.0000e-05\n",
      "Epoch 56/200\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 66.5243 - mae: 6.7162 - val_loss: 64.9117 - val_mae: 6.6487 - lr: 4.0000e-05\n",
      "Epoch 57/200\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 66.3401 - mae: 6.7103 - val_loss: 64.9138 - val_mae: 6.6465 - lr: 4.0000e-05\n",
      "Epoch 58/200\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 66.4389 - mae: 6.7102 - val_loss: 64.9231 - val_mae: 6.6500 - lr: 4.0000e-05\n",
      "Epoch 59/200\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 66.6218 - mae: 6.7210 - val_loss: 64.9328 - val_mae: 6.6521 - lr: 4.0000e-05\n",
      "Epoch 60/200\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 66.3163 - mae: 6.7047 - val_loss: 64.9040 - val_mae: 6.6444 - lr: 4.0000e-05\n",
      "Epoch 61/200\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 66.4188 - mae: 6.7118 - val_loss: 64.9097 - val_mae: 6.6463 - lr: 4.0000e-05\n",
      "Epoch 62/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 66.2515 - mae: 6.7045 - val_loss: 64.9089 - val_mae: 6.6460 - lr: 4.0000e-05\n",
      "Epoch 63/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 66.4536 - mae: 6.7073 - val_loss: 64.9279 - val_mae: 6.6506 - lr: 4.0000e-05\n",
      "Epoch 64/200\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 66.4026 - mae: 6.7134 - val_loss: 64.9193 - val_mae: 6.6488 - lr: 4.0000e-05\n",
      "Epoch 65/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 66.2922 - mae: 6.7049 - val_loss: 64.9346 - val_mae: 6.6553 - lr: 4.0000e-05\n",
      "Epoch 66/200\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 66.4735 - mae: 6.7159 - val_loss: 64.9147 - val_mae: 6.6443 - lr: 4.0000e-05\n",
      "Epoch 67/200\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 66.3707 - mae: 6.7074 - val_loss: 64.9125 - val_mae: 6.6474 - lr: 4.0000e-05\n",
      "Epoch 68/200\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 66.4544 - mae: 6.7148 - val_loss: 64.9074 - val_mae: 6.6504 - lr: 4.0000e-05\n",
      "Epoch 69/200\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 66.4359 - mae: 6.7149 - val_loss: 64.9136 - val_mae: 6.6478 - lr: 4.0000e-05\n",
      "Epoch 70/200\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 66.3013 - mae: 6.7107 - val_loss: 64.9161 - val_mae: 6.6465 - lr: 4.0000e-05\n",
      "Epoch 71/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 66.4714 - mae: 6.7112 - val_loss: 64.9182 - val_mae: 6.6459 - lr: 8.0000e-06\n",
      "Epoch 72/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 66.3257 - mae: 6.7082 - val_loss: 64.9143 - val_mae: 6.6486 - lr: 8.0000e-06\n",
      "Epoch 73/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 66.4961 - mae: 6.7103 - val_loss: 64.9200 - val_mae: 6.6467 - lr: 8.0000e-06\n",
      "Epoch 74/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 66.4067 - mae: 6.7104 - val_loss: 64.9122 - val_mae: 6.6456 - lr: 8.0000e-06\n",
      "Epoch 75/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 66.2098 - mae: 6.7003 - val_loss: 64.9085 - val_mae: 6.6451 - lr: 8.0000e-06\n",
      "Epoch 76/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 66.3685 - mae: 6.7114 - val_loss: 64.9146 - val_mae: 6.6461 - lr: 8.0000e-06\n",
      "Epoch 77/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 66.4640 - mae: 6.7111 - val_loss: 64.9168 - val_mae: 6.6460 - lr: 8.0000e-06\n",
      "Epoch 78/200\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 66.4614 - mae: 6.7093 - val_loss: 64.9160 - val_mae: 6.6460 - lr: 8.0000e-06\n",
      "Epoch 79/200\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 66.3073 - mae: 6.7054 - val_loss: 64.9062 - val_mae: 6.6441 - lr: 8.0000e-06\n",
      "Epoch 80/200\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 66.5057 - mae: 6.7162 - val_loss: 64.9186 - val_mae: 6.6446 - lr: 8.0000e-06\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('data_preview.csv')\n",
    "\n",
    "# Split into train and test\n",
    "X = data[['RMT %', 'AGE', 'Depression', 'Stress', 'Anxiety']]\n",
    "y = data['Depression.1']\n",
    "\n",
    "# # Feature scaling using StandardScaler\n",
    "# input_scaler = StandardScaler()\n",
    "# X_scaled = input_scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Deep neural network model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer with BatchNormalization\n",
    "model.add(BatchNormalization(input_shape=(X.shape[1],)))\n",
    "\n",
    "# Hidden layers with advanced features\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))  # Reduce dropout\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='Adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Advanced Callbacks: Early Stopping and ReduceLROnPlateau\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=1e-6)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=200,\n",
    "    callbacks=[early_stop, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n",
      "Predicted Depression: 22.90\n"
     ]
    }
   ],
   "source": [
    "x_in = [[0.35, 36, 35, 24, 38]] \n",
    "pred = model.predict(x_in)\n",
    "print(f'Predicted Depression: {pred[0][0]:.2f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('Depression_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 489ms/step\n",
      "Predicted Depression: 18.26\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('Depression_1.h5')\n",
    "\n",
    "x_in = [[0.4, 24, 42, 26, 16]] \n",
    "pred = model.predict(x_in)\n",
    "print(f'Predicted Depression: {pred[0][0]:.2f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "938/938 [==============================] - 10s 9ms/step - loss: 188.7634 - mae: 11.0904 - mse: 188.7634 - val_loss: 132.7402 - val_mae: 9.7778 - val_mse: 132.7402\n",
      "Epoch 2/20\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 135.2787 - mae: 9.9616 - mse: 135.2787 - val_loss: 131.2178 - val_mae: 9.7748 - val_mse: 131.2178\n",
      "Epoch 3/20\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 134.7287 - mae: 9.9430 - mse: 134.7287 - val_loss: 131.1253 - val_mae: 9.8590 - val_mse: 131.1253\n",
      "Epoch 4/20\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 134.1627 - mae: 9.9280 - mse: 134.1627 - val_loss: 129.9821 - val_mae: 9.8504 - val_mse: 129.9821\n",
      "Epoch 5/20\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 133.7288 - mae: 9.9201 - mse: 133.7288 - val_loss: 129.6216 - val_mae: 9.7746 - val_mse: 129.6216\n",
      "Epoch 6/20\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 133.4680 - mae: 9.9148 - mse: 133.4680 - val_loss: 130.4682 - val_mae: 9.8021 - val_mse: 130.4682\n",
      "Epoch 7/20\n",
      "938/938 [==============================] - 8s 8ms/step - loss: 133.2162 - mae: 9.9092 - mse: 133.2162 - val_loss: 130.1897 - val_mae: 9.8505 - val_mse: 130.1897\n",
      "Epoch 8/20\n",
      "938/938 [==============================] - 8s 8ms/step - loss: 133.4266 - mae: 9.9162 - mse: 133.4266 - val_loss: 129.6484 - val_mae: 9.7527 - val_mse: 129.6484\n",
      "Epoch 9/20\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 133.4522 - mae: 9.9160 - mse: 133.4522 - val_loss: 130.1167 - val_mae: 9.7547 - val_mse: 130.1167\n",
      "Epoch 10/20\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 133.0684 - mae: 9.9035 - mse: 133.0684 - val_loss: 129.6200 - val_mae: 9.7912 - val_mse: 129.6200\n",
      "Epoch 11/20\n",
      "938/938 [==============================] - 8s 8ms/step - loss: 132.8343 - mae: 9.9012 - mse: 132.8343 - val_loss: 130.0234 - val_mae: 9.8051 - val_mse: 130.0234\n",
      "Epoch 12/20\n",
      "938/938 [==============================] - 8s 8ms/step - loss: 132.7141 - mae: 9.8948 - mse: 132.7141 - val_loss: 129.7558 - val_mae: 9.8024 - val_mse: 129.7558\n",
      "Epoch 13/20\n",
      "938/938 [==============================] - 8s 8ms/step - loss: 132.8354 - mae: 9.9033 - mse: 132.8354 - val_loss: 129.8018 - val_mae: 9.7251 - val_mse: 129.8018\n",
      "Epoch 14/20\n",
      "938/938 [==============================] - 8s 8ms/step - loss: 132.6171 - mae: 9.8941 - mse: 132.6171 - val_loss: 130.1544 - val_mae: 9.8866 - val_mse: 130.1544\n",
      "Epoch 15/20\n",
      "938/938 [==============================] - 8s 8ms/step - loss: 132.6354 - mae: 9.9062 - mse: 132.6354 - val_loss: 129.9247 - val_mae: 9.8325 - val_mse: 129.9247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f6edef81f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#good one\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load data \n",
    "data = pd.read_csv('data_preview.csv')\n",
    "\n",
    "# # Normalize features\n",
    "# data = (data - data.mean()) / data.std()\n",
    "\n",
    "# Split into train and test\n",
    "X = data[['RMT %', 'AGE', 'Depression', 'Stress', 'Anxiety', 'Depression.1']]\n",
    "y = data['Depression.2']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y) \n",
    "\n",
    "# Deep neural network model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(256, activation='relu', input_dim=X.shape[1]))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(512))  \n",
    "model.add(BatchNormalization()) \n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "            \n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae', 'mse'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "model.fit(X_train, y_train, validation_split=0.2, \n",
    "          epochs=20, callbacks= early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F6EE237EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 140ms/step\n",
      "Predicted Depression: 16.54\n"
     ]
    }
   ],
   "source": [
    "x_in = [[0.32, 68, 38, 18, 8, 14]] \n",
    "pred = model.predict(x_in)\n",
    "print(f'Predicted Depression: {pred[0][0]:.2f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('Depression_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 133ms/step\n",
      "Predicted Depression: 11.46\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('Depression_2.h5')\n",
    "\n",
    "x_in = [[0.4, 72, 16, 14, 6, 12]] \n",
    "pred = model.predict(x_in)\n",
    "print(f'Predicted Depression: {pred[0][0]:.2f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 10s 7ms/step - loss: 106.8926 - mae: 7.8227 - val_loss: 47.4188 - val_mae: 5.3025 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 51.7586 - mae: 5.5666 - val_loss: 47.1157 - val_mae: 5.2925 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 50.6046 - mae: 5.4917 - val_loss: 47.1635 - val_mae: 5.2929 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 49.8673 - mae: 5.4488 - val_loss: 46.7245 - val_mae: 5.2738 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 49.3835 - mae: 5.4186 - val_loss: 46.7078 - val_mae: 5.2251 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 49.3323 - mae: 5.4126 - val_loss: 46.6531 - val_mae: 5.2626 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 7s 6ms/step - loss: 49.1334 - mae: 5.3991 - val_loss: 46.5037 - val_mae: 5.2134 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 48.9912 - mae: 5.3852 - val_loss: 46.5631 - val_mae: 5.2387 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 49.0784 - mae: 5.3887 - val_loss: 46.6471 - val_mae: 5.2491 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 48.8838 - mae: 5.3876 - val_loss: 46.4499 - val_mae: 5.2109 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 48.7604 - mae: 5.3735 - val_loss: 46.3908 - val_mae: 5.2087 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 48.6159 - mae: 5.3657 - val_loss: 46.5758 - val_mae: 5.2607 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 48.7289 - mae: 5.3662 - val_loss: 46.4462 - val_mae: 5.2025 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 48.4816 - mae: 5.3578 - val_loss: 46.4766 - val_mae: 5.2365 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 48.6181 - mae: 5.3663 - val_loss: 46.4265 - val_mae: 5.2096 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 48.4787 - mae: 5.3519 - val_loss: 46.4464 - val_mae: 5.2124 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 48.5377 - mae: 5.3514 - val_loss: 46.3481 - val_mae: 5.2066 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 48.5070 - mae: 5.3529 - val_loss: 46.3954 - val_mae: 5.2339 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 48.4072 - mae: 5.3498 - val_loss: 46.3544 - val_mae: 5.2053 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 48.3667 - mae: 5.3498 - val_loss: 46.5119 - val_mae: 5.2104 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('data_preview.csv')\n",
    "\n",
    "# Split into train and test\n",
    "X = data[['RMT %', 'AGE', 'Depression', 'Stress', 'Anxiety']]\n",
    "y = data['Stress.1']\n",
    "\n",
    "# # Feature scaling using StandardScaler\n",
    "# input_scaler = StandardScaler()\n",
    "# X_scaled = input_scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Deep neural network model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer with BatchNormalization\n",
    "model.add(BatchNormalization(input_shape=(X.shape[1],)))\n",
    "\n",
    "# Hidden layers with advanced features\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))  # Reduce dropout\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='Adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Advanced Callbacks: Early Stopping and ReduceLROnPlateau\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=1e-6)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,\n",
    "    callbacks=[early_stop, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 187ms/step\n",
      "Predicted Stress: 19.90\n"
     ]
    }
   ],
   "source": [
    "x_in = [[0.35, 36, 35, 24, 38]] \n",
    "pred = model.predict(x_in)\n",
    "print(f'Predicted Stress: {pred[0][0]:.2f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('Stress_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001DCDCB70790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 144ms/step\n",
      "Predicted Stress: 18.33\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('Stress_1.h5')\n",
    "\n",
    "x_in = [[0.4, 72, 16, 14, 6]] \n",
    "pred = model.predict(x_in)\n",
    "print(f'Predicted Stress: {pred[0][0]:.2f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 10s 7ms/step - loss: 72.0104 - mae: 5.7678 - val_loss: 56.3532 - val_mae: 5.1024 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 59.3222 - mae: 5.2459 - val_loss: 56.1874 - val_mae: 5.0755 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 58.7102 - mae: 5.2063 - val_loss: 55.6588 - val_mae: 5.0542 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 58.4965 - mae: 5.1908 - val_loss: 55.6575 - val_mae: 5.0943 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 58.3302 - mae: 5.1818 - val_loss: 55.6082 - val_mae: 5.0683 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 58.1355 - mae: 5.1722 - val_loss: 55.5774 - val_mae: 5.0817 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 58.0049 - mae: 5.1643 - val_loss: 55.5158 - val_mae: 5.0371 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 57.9528 - mae: 5.1613 - val_loss: 55.5444 - val_mae: 4.9788 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 57.8404 - mae: 5.1549 - val_loss: 55.7565 - val_mae: 5.0557 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 57.8590 - mae: 5.1543 - val_loss: 55.6070 - val_mae: 5.0645 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 57.8291 - mae: 5.1629 - val_loss: 55.9315 - val_mae: 4.9308 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 57.8493 - mae: 5.1573 - val_loss: 55.6140 - val_mae: 4.9942 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 57.7877 - mae: 5.1516 - val_loss: 55.4573 - val_mae: 5.0248 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 57.7024 - mae: 5.1527 - val_loss: 55.6895 - val_mae: 4.9567 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 57.7505 - mae: 5.1498 - val_loss: 55.5744 - val_mae: 4.9800 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 57.6754 - mae: 5.1462 - val_loss: 55.5239 - val_mae: 5.0492 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 57.7408 - mae: 5.1522 - val_loss: 55.4380 - val_mae: 5.0016 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 57.6100 - mae: 5.1462 - val_loss: 55.5194 - val_mae: 5.0765 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 57.7356 - mae: 5.1496 - val_loss: 55.4804 - val_mae: 5.0446 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 57.6930 - mae: 5.1463 - val_loss: 55.4896 - val_mae: 4.9888 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('data_preview.csv')\n",
    "\n",
    "# Split into train and test\n",
    "X = data[['RMT %', 'AGE', 'Depression', 'Stress', 'Anxiety', 'Stress.1']]\n",
    "y = data['Stress.2']\n",
    "\n",
    "# # Feature scaling using StandardScaler\n",
    "# input_scaler = StandardScaler()\n",
    "# X_scaled = input_scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Deep neural network model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer with BatchNormalization\n",
    "model.add(BatchNormalization(input_shape=(X.shape[1],)))\n",
    "\n",
    "# Hidden layers with advanced features\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))  # Reduce dropout\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='Adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Advanced Callbacks: Early Stopping and ReduceLROnPlateau\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=1e-6)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,\n",
    "    callbacks=[early_stop, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 252ms/step\n",
      "Predicted Stress: 11.57\n"
     ]
    }
   ],
   "source": [
    "x_in = [[0.48, 38, 26, 4, 22, 16]] \n",
    "pred = model.predict(x_in)\n",
    "print(f'Predicted Stress: {pred[0][0]:.2f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('Stress_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 201ms/step\n",
      "Predicted Stress: 11.57\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('Stress_2.h5')\n",
    "\n",
    "x_in = [[0.48, 38, 26, 4, 22, 16]] \n",
    "pred = model.predict(x_in)\n",
    "print(f'Predicted Stress: {pred[0][0]:.2f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 11s 7ms/step - loss: 138.5348 - mae: 9.6571 - val_loss: 89.4793 - val_mae: 8.1313 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 92.6044 - mae: 8.2783 - val_loss: 88.9434 - val_mae: 8.1444 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 91.4765 - mae: 8.2364 - val_loss: 88.8016 - val_mae: 8.1349 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 90.8802 - mae: 8.2243 - val_loss: 88.9216 - val_mae: 8.1266 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 90.5137 - mae: 8.2137 - val_loss: 88.6379 - val_mae: 8.1069 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 90.0436 - mae: 8.1880 - val_loss: 88.2365 - val_mae: 8.1133 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 89.8576 - mae: 8.1822 - val_loss: 88.1503 - val_mae: 8.1364 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 89.8335 - mae: 8.1827 - val_loss: 87.8926 - val_mae: 8.0918 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 89.6742 - mae: 8.1741 - val_loss: 87.9582 - val_mae: 8.0819 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 89.6192 - mae: 8.1744 - val_loss: 88.0315 - val_mae: 8.0830 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 89.4639 - mae: 8.1710 - val_loss: 87.6906 - val_mae: 8.0813 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 89.3509 - mae: 8.1629 - val_loss: 87.9840 - val_mae: 8.1239 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 89.3141 - mae: 8.1675 - val_loss: 87.7056 - val_mae: 8.0881 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 89.0827 - mae: 8.1525 - val_loss: 87.8841 - val_mae: 8.1019 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 89.1732 - mae: 8.1611 - val_loss: 87.8639 - val_mae: 8.0890 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 89.0979 - mae: 8.1558 - val_loss: 87.8075 - val_mae: 8.1037 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 89.1548 - mae: 8.1651 - val_loss: 87.8069 - val_mae: 8.0841 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 89.1141 - mae: 8.1605 - val_loss: 87.8065 - val_mae: 8.1125 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 89.1439 - mae: 8.1629 - val_loss: 87.9743 - val_mae: 8.1373 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 88.9229 - mae: 8.1541 - val_loss: 88.0613 - val_mae: 8.0822 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('data_preview.csv')\n",
    "\n",
    "# Split into train and test\n",
    "X = data[['RMT %', 'AGE', 'Depression', 'Stress', 'Anxiety']]\n",
    "y = data['Anxiety.1']\n",
    "\n",
    "# # Feature scaling using StandardScaler\n",
    "# input_scaler = StandardScaler()\n",
    "# X_scaled = input_scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Deep neural network model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer with BatchNormalization\n",
    "model.add(BatchNormalization(input_shape=(X.shape[1],)))\n",
    "\n",
    "# Hidden layers with advanced features\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))  # Reduce dropout\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='Adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Advanced Callbacks: Early Stopping and ReduceLROnPlateau\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=1e-6)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,\n",
    "    callbacks=[early_stop, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 98ms/step\n",
      "Predicted Anxiety: 10.63\n"
     ]
    }
   ],
   "source": [
    "x_in = [[0.43, 38, 26, 14, 12]] \n",
    "pred = model.predict(x_in)\n",
    "print(f'Predicted Anxiety: {pred[0][0]:.2f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('Anxiety_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001DCDCBD2820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 237ms/step\n",
      "Predicted Depression: 16.53\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('Anxiety_1.h5')\n",
    "\n",
    "x_in = [[0.35, 36, 35, 24, 38]] \n",
    "pred = model.predict(x_in)\n",
    "print(f'Predicted Depression: {pred[0][0]:.2f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1250/1250 [==============================] - 11s 7ms/step - loss: 80.4387 - mae: 6.7740 - val_loss: 50.5833 - val_mae: 5.3094 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 53.0742 - mae: 5.5185 - val_loss: 50.0396 - val_mae: 5.3057 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 52.5645 - mae: 5.4734 - val_loss: 49.8113 - val_mae: 5.2709 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 52.0539 - mae: 5.4358 - val_loss: 50.0093 - val_mae: 5.2630 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "1250/1250 [==============================] - 8s 6ms/step - loss: 51.7890 - mae: 5.4131 - val_loss: 49.6794 - val_mae: 5.2496 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 51.6513 - mae: 5.3983 - val_loss: 49.5819 - val_mae: 5.1889 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 51.4702 - mae: 5.3886 - val_loss: 49.6220 - val_mae: 5.2328 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 51.4005 - mae: 5.3814 - val_loss: 49.4442 - val_mae: 5.1944 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 51.1932 - mae: 5.3714 - val_loss: 49.5308 - val_mae: 5.2620 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 51.2307 - mae: 5.3698 - val_loss: 49.3910 - val_mae: 5.2276 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 51.1531 - mae: 5.3618 - val_loss: 49.3464 - val_mae: 5.2437 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 51.0364 - mae: 5.3549 - val_loss: 49.3275 - val_mae: 5.1940 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 50.8895 - mae: 5.3484 - val_loss: 49.3595 - val_mae: 5.2100 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 50.8538 - mae: 5.3461 - val_loss: 49.2943 - val_mae: 5.2046 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 51.0130 - mae: 5.3553 - val_loss: 49.3933 - val_mae: 5.1915 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 50.9058 - mae: 5.3461 - val_loss: 49.3000 - val_mae: 5.2233 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 50.8820 - mae: 5.3458 - val_loss: 49.4834 - val_mae: 5.1653 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 50.8459 - mae: 5.3489 - val_loss: 49.2849 - val_mae: 5.2002 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 50.9103 - mae: 5.3488 - val_loss: 49.3607 - val_mae: 5.1829 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 50.6751 - mae: 5.3332 - val_loss: 49.7812 - val_mae: 5.3686 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('data_preview.csv')\n",
    "\n",
    "# Split into train and test\n",
    "X = data[['RMT %', 'AGE', 'Depression', 'Stress', 'Anxiety', 'Anxiety.1']]\n",
    "y = data['Anxiety.2']\n",
    "\n",
    "# # Feature scaling using StandardScaler\n",
    "# input_scaler = StandardScaler()\n",
    "# X_scaled = input_scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Deep neural network model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer with BatchNormalization\n",
    "model.add(BatchNormalization(input_shape=(X.shape[1],)))\n",
    "\n",
    "# Hidden layers with advanced features\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))  # Reduce dropout\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='Adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Advanced Callbacks: Early Stopping and ReduceLROnPlateau\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=1e-6)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=20,\n",
    "    callbacks=[early_stop, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node sequential_8/batch_normalization_30/batchnorm/mul_1 defined at (most recent call last):\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n\n  File \"C:\\Users\\Ritesh\\AppData\\Local\\Temp\\ipykernel_23880\\372391797.py\", line 2, in <cell line: 2>\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2631, in predict\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2416, in predict_function\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2401, in step_function\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2389, in run_step\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2357, in predict_step\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 589, in __call__\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\sequential.py\", line 398, in call\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\functional.py\", line 515, in call\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\functional.py\", line 672, in _run_internal_graph\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py\", line 788, in call\n\nIncompatible shapes: [1,6] vs. [5]\n\t [[{{node sequential_8/batch_normalization_30/batchnorm/mul_1}}]] [Op:__inference_predict_function_4236]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Ritesh\\Desktop\\Mental Health Using Genetic Algorithm and Machine Learning\\final.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ritesh/Desktop/Mental%20Health%20Using%20Genetic%20Algorithm%20and%20Machine%20Learning/final.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m x_in \u001b[39m=\u001b[39m [[\u001b[39m0.35\u001b[39m, \u001b[39m36\u001b[39m, \u001b[39m35\u001b[39m, \u001b[39m24\u001b[39m, \u001b[39m38\u001b[39m, \u001b[39m10\u001b[39m]] \n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Ritesh/Desktop/Mental%20Health%20Using%20Genetic%20Algorithm%20and%20Machine%20Learning/final.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(x_in)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ritesh/Desktop/Mental%20Health%20Using%20Genetic%20Algorithm%20and%20Machine%20Learning/final.ipynb#X30sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPredicted Depression: \u001b[39m\u001b[39m{\u001b[39;00mpred[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sequential_8/batch_normalization_30/batchnorm/mul_1 defined at (most recent call last):\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 197, in _run_module_as_main\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\runpy.py\", line 87, in _run_code\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\traitlets\\config\\application.py\", line 976, in launch_instance\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 596, in run_forever\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\base_events.py\", line 1890, in _run_once\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n\n  File \"C:\\Users\\Ritesh\\AppData\\Local\\Temp\\ipykernel_23880\\372391797.py\", line 2, in <cell line: 2>\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2631, in predict\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2416, in predict_function\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2401, in step_function\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2389, in run_step\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 2357, in predict_step\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 589, in __call__\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\sequential.py\", line 398, in call\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\functional.py\", line 515, in call\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\functional.py\", line 672, in _run_internal_graph\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py\", line 788, in call\n\nIncompatible shapes: [1,6] vs. [5]\n\t [[{{node sequential_8/batch_normalization_30/batchnorm/mul_1}}]] [Op:__inference_predict_function_4236]"
     ]
    }
   ],
   "source": [
    "x_in = [[0.35, 36, 35, 24, 38, 10]] \n",
    "pred = model.predict(x_in)\n",
    "print(f'Predicted Depression: {pred[0][0]:.2f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('Anxiety_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 146ms/step\n",
      "Predicted Depression: 15.22\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('Anxiety_2.h5')\n",
    "\n",
    "x_in = [[0.35, 36, 35, 24, 38, 10]] \n",
    "pred = model.predict(x_in)\n",
    "print(f'Predicted Depression: {pred[0][0]:.2f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1250/1250 [==============================] - 11s 7ms/step - loss: 54.3855 - mae: 5.5368 - val_loss: 35.6446 - val_mae: 4.6343 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 37.2854 - mae: 4.6906 - val_loss: 34.9225 - val_mae: 4.5509 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 36.5436 - mae: 4.6447 - val_loss: 34.9730 - val_mae: 4.5688 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 36.1829 - mae: 4.6263 - val_loss: 34.6746 - val_mae: 4.6497 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 35.9775 - mae: 4.6196 - val_loss: 34.6841 - val_mae: 4.6534 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 35.9556 - mae: 4.6189 - val_loss: 34.6616 - val_mae: 4.4929 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 35.7242 - mae: 4.6044 - val_loss: 34.5522 - val_mae: 4.5342 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 35.6808 - mae: 4.6019 - val_loss: 34.6081 - val_mae: 4.5603 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 35.6455 - mae: 4.5993 - val_loss: 34.6071 - val_mae: 4.5255 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 35.5374 - mae: 4.5988 - val_loss: 34.6676 - val_mae: 4.4409 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 35.5927 - mae: 4.5936 - val_loss: 34.6936 - val_mae: 4.5954 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 35.5026 - mae: 4.5970 - val_loss: 34.5330 - val_mae: 4.5321 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 35.4942 - mae: 4.5921 - val_loss: 34.6430 - val_mae: 4.5820 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 35.4757 - mae: 4.5984 - val_loss: 34.5629 - val_mae: 4.5262 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 35.4329 - mae: 4.5916 - val_loss: 34.6706 - val_mae: 4.4222 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 35.4148 - mae: 4.5886 - val_loss: 34.5496 - val_mae: 4.5456 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 35.4269 - mae: 4.5924 - val_loss: 34.6113 - val_mae: 4.5961 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 35.4345 - mae: 4.5964 - val_loss: 34.5586 - val_mae: 4.4688 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 35.3745 - mae: 4.5878 - val_loss: 34.8304 - val_mae: 4.3888 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 35.3743 - mae: 4.5863 - val_loss: 34.7220 - val_mae: 4.6545 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 35.3967 - mae: 4.5933 - val_loss: 34.5506 - val_mae: 4.4661 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 35.3618 - mae: 4.5882 - val_loss: 34.5472 - val_mae: 4.5464 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "1250/1250 [==============================] - 8s 7ms/step - loss: 35.2127 - mae: 4.5793 - val_loss: 34.5334 - val_mae: 4.5029 - lr: 2.0000e-04\n",
      "Epoch 24/50\n",
      "1250/1250 [==============================] - 10s 8ms/step - loss: 35.1988 - mae: 4.5794 - val_loss: 34.5658 - val_mae: 4.4793 - lr: 2.0000e-04\n",
      "Epoch 25/50\n",
      "1250/1250 [==============================] - 11s 9ms/step - loss: 35.0732 - mae: 4.5676 - val_loss: 34.5624 - val_mae: 4.5539 - lr: 2.0000e-04\n",
      "Epoch 26/50\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 35.1711 - mae: 4.5783 - val_loss: 34.5618 - val_mae: 4.5254 - lr: 2.0000e-04\n",
      "Epoch 27/50\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 35.1530 - mae: 4.5704 - val_loss: 34.6302 - val_mae: 4.6323 - lr: 2.0000e-04\n",
      "Epoch 28/50\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 35.1783 - mae: 4.5825 - val_loss: 34.5713 - val_mae: 4.5287 - lr: 2.0000e-04\n",
      "Epoch 29/50\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 35.1493 - mae: 4.5741 - val_loss: 34.6095 - val_mae: 4.4937 - lr: 2.0000e-04\n",
      "Epoch 30/50\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 35.1819 - mae: 4.5761 - val_loss: 34.6029 - val_mae: 4.5051 - lr: 2.0000e-04\n",
      "Epoch 31/50\n",
      "1250/1250 [==============================] - 9s 7ms/step - loss: 35.1534 - mae: 4.5701 - val_loss: 34.6141 - val_mae: 4.5408 - lr: 2.0000e-04\n",
      "Epoch 32/50\n",
      "1250/1250 [==============================] - 9s 8ms/step - loss: 35.1141 - mae: 4.5698 - val_loss: 34.6202 - val_mae: 4.5755 - lr: 2.0000e-04\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('data_preview.csv')\n",
    "\n",
    "# Split into train and test\n",
    "X = data[['RMT %', 'AGE', 'Depression', 'Stress', 'Anxiety', 'Depression.1', 'Stress.1', 'Anxiety.1' ]]\n",
    "y = data['Total Score.1']\n",
    "\n",
    "# # Feature scaling using StandardScaler\n",
    "# input_scaler = StandardScaler()\n",
    "# X_scaled = input_scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Deep neural network model\n",
    "model = Sequential()\n",
    "\n",
    "# Input layer with BatchNormalization\n",
    "model.add(BatchNormalization(input_shape=(X.shape[1],)))\n",
    "\n",
    "# Hidden layers with advanced features\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))  # Reduce dropout\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='Adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Advanced Callbacks: Early Stopping and ReduceLROnPlateau\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=10, min_lr=1e-6)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    callbacks=[early_stop, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 170ms/step\n",
      "Predicted Anxiety: 11.25\n"
     ]
    }
   ],
   "source": [
    "x_in = [[0.48, 38, 26, 22, 4, 14, 8, 2]] \n",
    "pred = model.predict(x_in)\n",
    "print(f'Predicted Anxiety: {pred[0][0]:.2f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ritesh\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('Total_Score_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 127ms/step\n",
      "Predicted Anxiety: 11.25\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('Total_Score_1.h5')\n",
    "\n",
    "x_in = [[0.48, 38, 26, 22, 4, 14, 8, 2]] \n",
    "pred = model.predict(x_in)\n",
    "print(f'Predicted Anxiety: {pred[0][0]:.2f}') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
